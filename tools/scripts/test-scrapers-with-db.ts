import { count } from "drizzle-orm";

import { db } from "../../src/lib/db";
import { scrapedContent } from "../../src/lib/db/schema";
import { ScraperManager } from "../../src/lib/services/scraping/scraper-manager";

async function testScrapersWithDatabase() {
  console.log("ğŸš€ Testing Morning Pod Scrapers with Database Persistence...");

  // Check initial database state
  const [initialCount] = await db
    .select({ count: count() })
    .from(scrapedContent);
  console.log(`ğŸ“Š Initial database content count: ${initialCount.count}`);

  const manager = new ScraperManager({
    deduplicationEnabled: true,
    persistToDatabase: true, // Enable database persistence
  });

  try {
    console.log("\nğŸ“¡ Running scrapers with database persistence...");
    const result = await manager.scrapeAll();

    console.log("\nğŸ“Š Scraping Results:");
    console.log(`âœ… Success: ${result.success}`);
    console.log(`ğŸ“° Total Items Scraped: ${result.totalItems}`);
    console.log(`ğŸ”„ Unique Items: ${result.uniqueItems}`);
    console.log(`âŒ Duplicates Removed: ${result.duplicatesRemoved}`);

    // Check database state after scraping
    const [finalCount] = await db
      .select({ count: count() })
      .from(scrapedContent);
    console.log("\nğŸ’¾ Database Results:");
    console.log(`ğŸ“Š Final database content count: ${finalCount.count}`);
    console.log(`â• New items saved: ${finalCount.count - initialCount.count}`);

    // Show some sample content from database
    const sampleContent = await db
      .select({
        category: scrapedContent.category,
        id: scrapedContent.id,
        scrapedAt: scrapedContent.scrapedAt,
        source: scrapedContent.source,
        status: scrapedContent.status,
        title: scrapedContent.title,
      })
      .from(scrapedContent)
      .orderBy(scrapedContent.scrapedAt)
      .limit(5);

    console.log("\nğŸ“‹ Sample Database Content:");
    for (const [index, item] of sampleContent.entries()) {
      console.log(`${index + 1}. [${item.source}] ${item.title}`);
      console.log(`   Category: ${item.category} | Status: ${item.status}`);
      console.log(`   Scraped: ${item.scrapedAt?.toISOString()}`);
      console.log("");
    }

    // Test deduplication by running again
    console.log("ğŸ”„ Testing deduplication by running scrapers again...");
    const secondResult = await manager.scrapeAll();

    const [afterSecondRun] = await db
      .select({ count: count() })
      .from(scrapedContent);
    console.log("\nğŸ” Deduplication Test Results:");
    console.log(`ğŸ“° Second run items: ${secondResult.totalItems}`);
    console.log(`ğŸ’¾ Database count after second run: ${afterSecondRun.count}`);
    console.log(
      `âœ… Deduplication working: ${afterSecondRun.count === finalCount.count ? "YES" : "NO"}`
    );
  } catch (error) {
    console.error("âŒ Error during scraping:", error);
  }
}

// Run the test
testScrapersWithDatabase()
  .then(() => {
    console.log("\nâœ… Test completed successfully!");
    process.exit(0);
  })
  .catch((error) => {
    console.error("âŒ Test failed:", error);
    process.exit(1);
  });
